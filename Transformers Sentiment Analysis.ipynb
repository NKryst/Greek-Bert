{
 "cells": [
  {
   "source": [
    "### This is my notebook on Transformers sentiment analysis in English"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997795224189758}]"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "classifier('We are very happy to show you the 🤗 Transformers library.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = classifier([\"We are very happy to show you the 🤗 Transformers library.\", \"We hope you don't hate it.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "label: POSITIVE, with score: 0.9998\nlabel: NEGATIVE, with score: 0.5309\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "OSError",
     "evalue": "Can't load config for 'nlpaued/bert-base-greek-uncased-v1'. Make sure that:\n\n- 'nlpaued/bert-base-greek-uncased-v1' is a correct model identifier listed on 'https://huggingface.co/models'\n\n- or 'nlpaued/bert-base-greek-uncased-v1' is the correct path to a directory containing a config.json file\n\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresolved_config_file\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m             \u001b[0mconfig_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dict_from_json_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresolved_config_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-93aff3ff3858>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sentiment-analysis'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"nlpaued/bert-base-greek-uncased-v1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines.py\u001b[0m in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, framework, **kwargs)\u001b[0m\n\u001b[0;32m   2714\u001b[0m             \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2715\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2716\u001b[1;33m             \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2717\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2718\u001b[0m     \u001b[1;31m# Instantiate config if needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"config\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"bert-base-japanese\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    308\u001b[0m             \u001b[1;33m{\u001b[0m\u001b[1;34m'foo'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m         \"\"\"\n\u001b[1;32m--> 310\u001b[1;33m         \u001b[0mconfig_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"model_type\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    366\u001b[0m                 \u001b[1;34mf\"- or '{pretrained_model_name_or_path}' is the correct path to a directory containing a {CONFIG_NAME} file\\n\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m             )\n\u001b[1;32m--> 368\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Can't load config for 'nlpaued/bert-base-greek-uncased-v1'. Make sure that:\n\n- 'nlpaued/bert-base-greek-uncased-v1' is a correct model identifier listed on 'https://huggingface.co/models'\n\n- or 'nlpaued/bert-base-greek-uncased-v1' is the correct path to a directory containing a config.json file\n\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('sentiment-analysis', model=\"nlpaued/bert-base-greek-uncased-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 100%|██████████| 953/953 [00:00<?, ?B/s] \n",
      "Downloading: 100%|██████████| 669M/669M [01:52<00:00, 5.95MB/s]\n",
      "Downloading: 100%|██████████| 872k/872k [00:01<00:00, 632kB/s]\n",
      "Downloading: 100%|██████████| 112/112 [00:00<?, ?B/s] \n",
      "Downloading: 100%|██████████| 39.0/39.0 [00:00<00:00, 4.88kB/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "source": [
    "Parenthesis to check Greek Bert as it was published from NLP AUEB"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "αυτη ειναι η ελληνικη εκδοση του bert.\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def strip_accents_and_lowercase(s):\n",
    "   return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                  if unicodedata.category(c) != 'Mn').lower()\n",
    "\n",
    "accented_string = \"Αυτή είναι η Ελληνική έκδοση του BERT.\"\n",
    "unaccented_string = strip_accents_and_lowercase(accented_string)\n",
    "\n",
    "print(unaccented_string) # αυτη ειναι η ελληνικη εκδοση του bert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 100%|██████████| 459/459 [00:00<?, ?B/s] \n",
      "Downloading: 100%|██████████| 530k/530k [00:01<00:00, 464kB/s] \n",
      "Downloading: 100%|██████████| 112/112 [00:00<00:00, 14.1kB/s]\n",
      "Downloading: 100%|██████████| 2.00/2.00 [00:00<00:00, 239B/s]\n",
      "Downloading: 100%|██████████| 454M/454M [01:20<00:00, 5.63MB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/bert-base-greek-uncased-v1\")\n",
    "model = AutoModel.from_pretrained(\"nlpaueb/bert-base-greek-uncased-v1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\nickr\\anaconda3\\lib\\site-packages\\transformers\\modeling_auto.py:781: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at nlpaueb/bert-base-greek-uncased-v1 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "['[CLS]', 'o', 'ποιητης', 'εγραψε', 'ενα', '[MASK]', '.', '[SEP]']\n",
      "τραγουδι\n",
      "['[CLS]', 'o', 'ποιητης', 'εγραψε', 'ενα', '[MASK]', '.', '[SEP]']\n",
      "εγραψε\n",
      "['[CLS]', 'ειναι', 'ενας', '[MASK]', 'ανθρωπος', 'και', 'κανει', 'συχνα', '[MASK]', '.', '[SEP]']\n",
      "ταξιδια\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import *\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer_greek = AutoTokenizer.from_pretrained('nlpaueb/bert-base-greek-uncased-v1')\n",
    "lm_model_greek = AutoModelWithLMHead.from_pretrained('nlpaueb/bert-base-greek-uncased-v1')\n",
    "\n",
    "# ================ EXAMPLE 1 ================\n",
    "text_1 = 'O ποιητής έγραψε ένα [MASK] .'\n",
    "# EN: 'The poet wrote a [MASK].'\n",
    "input_ids = tokenizer_greek.encode(text_1)\n",
    "print(tokenizer_greek.convert_ids_to_tokens(input_ids))\n",
    "# ['[CLS]', 'o', 'ποιητης', 'εγραψε', 'ενα', '[MASK]', '.', '[SEP]']\n",
    "outputs = lm_model_greek(torch.tensor([input_ids]))[0]\n",
    "print(tokenizer_greek.convert_ids_to_tokens(outputs[0, 5].max(0)[1].item()))\n",
    "# the most plausible prediction for [MASK] is \"song\"\n",
    "\n",
    "# ================ EXAMPLE 2 ================\n",
    "text_2 = 'Είναι ένας [MASK] άνθρωπος.'\n",
    "# EN: 'He is a [MASK] person.'\n",
    "input_ids = tokenizer_greek.encode(text_1)\n",
    "print(tokenizer_greek.convert_ids_to_tokens(input_ids))\n",
    "# ['[CLS]', 'ειναι', 'ενας', '[MASK]', 'ανθρωπος', '.', '[SEP]']\n",
    "outputs = lm_model_greek(torch.tensor([input_ids]))[0]\n",
    "print(tokenizer_greek.convert_ids_to_tokens(outputs[0, 3].max(0)[1].item()))\n",
    "# the most plausible prediction for [MASK] is \"good\"\n",
    "\n",
    "# ================ EXAMPLE 3 ================\n",
    "text_3 = 'Είναι ένας [MASK] άνθρωπος και κάνει συχνά [MASK].'\n",
    "# EN: 'He is a [MASK] person he does frequently [MASK].'\n",
    "input_ids = tokenizer_greek.encode(text_3)\n",
    "print(tokenizer_greek.convert_ids_to_tokens(input_ids))\n",
    "# ['[CLS]', 'ειναι', 'ενας', '[MASK]', 'ανθρωπος', 'και', 'κανει', 'συχνα', '[MASK]', '.', '[SEP]']\n",
    "outputs = lm_model_greek(torch.tensor([input_ids]))[0]\n",
    "print(tokenizer_greek.convert_ids_to_tokens(outputs[0, 8].max(0)[1].item()))\n",
    "# the most plausible prediction for the second [MASK] is \"trips\"\n"
   ]
  },
  {
   "source": [
    "Back to English instructions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"We are very happy to show you the 🤗 Transformers library.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$x_{1} + x_{2} + \\cdots + x_{n}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('this', 'is')\n('is', 'a')\n('a', 'foo')\n('foo', 'bar')\n('bar', 'sentences')\n('sentences', 'and')\n('and', 'i')\n('i', 'want')\n('want', 'to')\n('to', 'ngramize')\n('ngramize', 'it')\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "sentence = 'this is a foo bar sentences and i want to ngramize it'\n",
    "\n",
    "n = 2\n",
    "sixgrams = ngrams(sentence.split(), n)\n",
    "\n",
    "for grams in sixgrams:\n",
    "  print (grams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "__________________________________________________\nTitle-- Spain, Greece and US holidays 'optimistically' boosted ahead ...\nDate/Time-- 39 mins ago\ndescription-- SPAIN, Greece and the USA all did not make the Government's travel \"green list\" on Friday. However, with the list set to be reviewed every three weeks, it seems ...\nLink-- https://www.express.co.uk/travel/articles/1433791/spain-greece-us-holidays-green-list-travel-bookings-review\n__________________________________________________\nTitle-- High Bar for Proof Limits Interest for Greek Citizenship Test\nDate/Time-- 53 mins ago\ndescription-- ... in Greece for at least several years. “Interest is already great for the exams scheduled to take place in September,” they added without explaining why it wasn't ...\nLink-- https://www.thenationalherald.com/archive_general_news_greece/arthro/high_bar_for_proof_limits_interest_for_greek_citizenship_test-2397515/\n__________________________________________________\nTitle-- Woman in Athens Acid Attack Charged With Attempted Murder\nDate/Time-- 57 mins ago\ndescription-- United States · Greece · World · Obituaries · Memorials ... Columnists · Letter to Editor · Dear Stavroula · Guest Viewpoints · GREECE ... Renting in Greece.\nLink-- https://www.thenationalherald.com/archive_general_news_greece/arthro/woman_in_athens_acid_attack_charged_with_attempted_murder-2397519/\n__________________________________________________\nTitle-- Greek Judges Cite Social Media Bullying Over Custody Cases\nDate/Time-- 58 mins ago\ndescription-- ATHENS – With proposed reforms from the New Democracy government over parental roles in divorce cases drawing fire from critics, judges in Greece revealed ...\nLink-- https://www.thenationalherald.com/archive_general_news_greece/arthro/greek_judges_cite_social_media_bullying_over_custody_cases-2397517/\n__________________________________________________\nTitle-- COVID-19 | Hoping To Lure Back Tourists, Greece Reopens ...\nDate/Time-- 1 hour ago\ndescription-- With widely spaced sun loungers and regular disinfections, Greece reopened its organised beaches on May 8 as the popular Mediterranean holiday destination ...\nLink-- https://www.moneycontrol.com/news/photos/world/covid-19-hoping-to-lure-back-tourists-greece-reopens-beaches-despite-pandemic-6872581.html\n__________________________________________________\nTitle-- Greece Marks Europe Day 2021 with Acropolis Ceremony\nDate/Time-- 1 hour ago\ndescription-- The flags of Greece and the European Union were raised at the Acropolis early on Sunday in celebration of “Europe Day 2021”. The ceremony was attended by ...\nLink-- https://greekreporter.com/2021/05/09/greece-marks-europe-day-2021-acropolis-ceremony/\n__________________________________________________\nTitle-- Reopening of Sports Facilities in Greece Moves Forward with ...\nDate/Time-- 1 hour ago\ndescription-- Reopening of Sports Facilities in Greece Moves Forward with Joint Ministerial Decision. Ευρωκίνηση. Deputy Sports Minister Lefteris Avgenakis. (Photo by ...\nLink-- https://www.thenationalherald.com/sports_greece/arthro/reopening_of_sports_facilities_in_greece_moves_forward_with_joint_ministerial_decision-2397512/\n__________________________________________________\nTitle-- A Slice of Greece Down Under: Australia Cliffs Resemble ...\nDate/Time-- 2 hours ago\ndescription-- Australia has banned foreign travel, Australians cannot fly to Greece, but at least they can enjoy diving into turquoise waters off a hidden cliff that resembles an ...\nLink-- https://greekreporter.com/2021/05/09/slice-of-greece-down-under-australia-cliffs-resemble-aegean-island/\n__________________________________________________\nTitle-- Greece to End SMS System for Circulating Outside Home on ...\nDate/Time-- 3 hours ago\ndescription-- Greece to End SMS System for Circulating Outside Home on May 14. Αssociated Press. Two men wearing face masks to protect against coronavirus, walk as a ...\nLink-- https://www.thenationalherald.com/archive_general_news_greece/arthro/greece_to_end_sms_system_for_circulating_outside_home_on_may_14-2396918/\n__________________________________________________\nTitle-- Greek Businessman Thanassis Lavidas of Lavipharm Dies ...\nDate/Time-- 3 hours ago\ndescription-- Lavidas also chaired the Greece-US Business Council, and had been recognized by France as a Chevalier of the Legion of Honor in 2011 for promoting ...\nLink-- https://www.thenationalherald.com/archive_general_news_greece/arthro/greek_businessman_thanassis_lavidas_of_lavipharm_dies_aged_73-2396917/\n"
     ]
    }
   ],
   "source": [
    "from GoogleNews import GoogleNews\n",
    "\n",
    "googlenews = GoogleNews()\n",
    "googlenews = GoogleNews(period ='7d')\n",
    "googlenews.search('Greece')\n",
    "result=googlenews.result()\n",
    "for x in result:\n",
    "    print(\"_\"*50)\n",
    "    print(\"Title--\",x['title'])\n",
    "    print(\"Date/Time--\",x['date'])\n",
    "    print(\"description--\",x['desc'])\n",
    "    print(\"Link--\",x['link'])\n",
    "    write.csv()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python383jvsc74a57bd0d1aaa45cf9320fce199f7bc660ffa5b83aa7a79386c720dbbce53fcf8e406d53",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}